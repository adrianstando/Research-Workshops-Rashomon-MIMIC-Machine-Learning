{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Praca domowa nr 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Budowanie modelu na podstawie artykułu: https://academic.oup.com/jamiaopen/article/1/1/87/5032901\n",
    "\n",
    "Przed operacjami w tym notebooku, został użyty skrypt do preprecessingu załączony do wymienionego wyżej artykułu, który jest dostępny tutaj: https://github.com/illidanlab/urgent-care-comparative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zadanie: problem klasyfikacji, predykcja śmiertelności na podstawie przedstawienia danych w postaci *X48* (wg. artykułu powyżej)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biblioteki + dodatkowe funkcje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "from sklearn.metrics import roc_curve, auc as auc_score, confusion_matrix, f1_score\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funkcja z repozytorium reprodukowanego artykułu\n",
    "def single_score(y_te, yhat):\n",
    "    fpr, tpr, thresholds = roc_curve(y_te, yhat)\n",
    "    roc_auc = auc_score(fpr, tpr)\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    yhat[yhat>=optimal_threshold]=1; yhat[yhat<optimal_threshold]=0\n",
    "    yhat=[int(i) for i in yhat]\n",
    "    #matrix = confusion_matrix(y_te, yhat)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_te, yhat).ravel()\n",
    "    sen=1.0* (tp/(tp+fn))\n",
    "    spec=1.0* (tn/(tn+fp))\n",
    "    f1=f1_score(y_te,yhat)\n",
    "    return roc_auc, f1, sen, spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funkcja z repozytorium reprodukowanego artykułu\n",
    "def balanced_subsample(x,y,subsample_size=1.0):\n",
    "    class_xs = []\n",
    "    min_elems = None\n",
    "    for yi in np.unique(y):\n",
    "        elems = x[(y == yi)]\n",
    "        class_xs.append((yi, elems))\n",
    "        if min_elems == None or elems.shape[0] < min_elems:\n",
    "            min_elems = elems.shape[0]\n",
    "    use_elems = min_elems\n",
    "    if subsample_size < 1:\n",
    "        use_elems = int(min_elems*subsample_size)\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for ci,this_xs in class_xs:\n",
    "        if len(this_xs) > use_elems:\n",
    "            np.random.shuffle(this_xs)\n",
    "\n",
    "        x_ = this_xs[:use_elems]\n",
    "        y_ = np.empty(use_elems)\n",
    "        y_.fill(ci)\n",
    "\n",
    "        xs.append(x_)\n",
    "        ys.append(y_)\n",
    "\n",
    "    xs = np.concatenate(xs)\n",
    "    ys = np.concatenate(ys)\n",
    "\n",
    "    return xs,ys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Załadowanie danych po preprocessingu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.22535211e-02, 0.00000000e+00, 5.43478261e-02, ...,\n",
       "        4.03017024e-01, 1.33952979e-01, 4.75067826e-01],\n",
       "       [2.58215962e-01, 1.18421053e-01, 3.26086957e-01, ...,\n",
       "        4.10958588e-14, 0.00000000e+00, 0.00000000e+00],\n",
       "       [2.11267606e-01, 4.05553814e-01, 8.69565217e-02, ...,\n",
       "        2.52207581e-01, 1.88907108e-01, 2.31845699e-01],\n",
       "       ...,\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        4.10958588e-14, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 2.10526316e-01, 0.00000000e+00, ...,\n",
       "        2.64952543e-01, 2.88610525e-01, 4.89848547e-02],\n",
       "       [3.20522201e-01, 1.57894737e-01, 0.00000000e+00, ...,\n",
       "        4.83805376e-02, 3.83338758e-02, 1.06946021e-01]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.load(\"X48.npy\")\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('y', 'rb') as f:\n",
    "    labels = pickle.load(f)\n",
    "    \n",
    "task = [yy[0] for yy in labels]\n",
    "y = np.array(task)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelowanie z kroswalidacją"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "TRAIN: [ 4964  4971  4994 ... 27613 27614 27615] TEST: [   0    1    2 ... 5602 5603 5604]\n",
      "Iteration:  1\n",
      "TRAIN: [    0     1     2 ... 27613 27614 27615] TEST: [ 4964  4971  4994 ... 11217 11218 11219]\n",
      "Iteration:  2\n",
      "TRAIN: [    0     1     2 ... 27613 27614 27615] TEST: [ 9861  9876  9893 ... 16776 16777 16778]\n",
      "Iteration:  3\n",
      "TRAIN: [    0     1     2 ... 27613 27614 27615] TEST: [14885 14892 14917 ... 22221 22222 22223]\n",
      "Iteration:  4\n",
      "TRAIN: [    0     1     2 ... 22221 22222 22223] TEST: [20978 20997 21005 ... 27613 27614 27615]\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits = 5)\n",
    "count = 0\n",
    "data = [None] * 5\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    print(\"Iteration: \", count)\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # model = RF(n_estimators = 450, verbose = 1)\n",
    "    model = RF(n_estimators = 450)\n",
    "    \n",
    "    xs, ys = balanced_subsample(X_train, y_train, 1)\n",
    "    \n",
    "    model = model.fit(xs, ys)\n",
    "    \n",
    "    yhat = model.predict(X_train)\n",
    "    tr_auc, _, _, _ = single_score(y_train, yhat)\n",
    "    \n",
    "    yhat2 = model.predict(X_test)\n",
    "    te_auc, f1_scor, sen, spec = single_score(y_test, yhat2)\n",
    "    \n",
    "    data[count] = {'train_auc' : tr_auc, 'test_auc' : te_auc, 'test_f1_score' : f1_scor, 'test_sen(precision)' : sen, 'test_spec(recall)' : spec}\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_auc</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>test_f1_score</th>\n",
       "      <th>test_sen(precision)</th>\n",
       "      <th>test_spec(recall)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.885757</td>\n",
       "      <td>0.768931</td>\n",
       "      <td>0.426632</td>\n",
       "      <td>0.804203</td>\n",
       "      <td>0.733658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.001229</td>\n",
       "      <td>0.010809</td>\n",
       "      <td>0.008064</td>\n",
       "      <td>0.036333</td>\n",
       "      <td>0.019665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.884598</td>\n",
       "      <td>0.755724</td>\n",
       "      <td>0.418002</td>\n",
       "      <td>0.755690</td>\n",
       "      <td>0.709147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.884951</td>\n",
       "      <td>0.762562</td>\n",
       "      <td>0.420418</td>\n",
       "      <td>0.792109</td>\n",
       "      <td>0.721069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.885163</td>\n",
       "      <td>0.770355</td>\n",
       "      <td>0.424733</td>\n",
       "      <td>0.793627</td>\n",
       "      <td>0.731497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.886576</td>\n",
       "      <td>0.771466</td>\n",
       "      <td>0.433735</td>\n",
       "      <td>0.831563</td>\n",
       "      <td>0.750822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.887496</td>\n",
       "      <td>0.784547</td>\n",
       "      <td>0.436272</td>\n",
       "      <td>0.848024</td>\n",
       "      <td>0.755757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       train_auc  test_auc  test_f1_score  test_sen(precision)  \\\n",
       "count   5.000000  5.000000       5.000000             5.000000   \n",
       "mean    0.885757  0.768931       0.426632             0.804203   \n",
       "std     0.001229  0.010809       0.008064             0.036333   \n",
       "min     0.884598  0.755724       0.418002             0.755690   \n",
       "25%     0.884951  0.762562       0.420418             0.792109   \n",
       "50%     0.885163  0.770355       0.424733             0.793627   \n",
       "75%     0.886576  0.771466       0.433735             0.831563   \n",
       "max     0.887496  0.784547       0.436272             0.848024   \n",
       "\n",
       "       test_spec(recall)  \n",
       "count           5.000000  \n",
       "mean            0.733658  \n",
       "std             0.019665  \n",
       "min             0.709147  \n",
       "25%             0.721069  \n",
       "50%             0.731497  \n",
       "75%             0.750822  \n",
       "max             0.755757  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "TRAIN: [ 4964  4971  4994 ... 27613 27614 27615] TEST: [   0    1    2 ... 5602 5603 5604]\n",
      "Iteration:  1\n",
      "TRAIN: [    0     1     2 ... 27613 27614 27615] TEST: [ 4964  4971  4994 ... 11217 11218 11219]\n",
      "Iteration:  2\n",
      "TRAIN: [    0     1     2 ... 27613 27614 27615] TEST: [ 9861  9876  9893 ... 16776 16777 16778]\n",
      "Iteration:  3\n",
      "TRAIN: [    0     1     2 ... 27613 27614 27615] TEST: [14885 14892 14917 ... 22221 22222 22223]\n",
      "Iteration:  4\n",
      "TRAIN: [    0     1     2 ... 22221 22222 22223] TEST: [20978 20997 21005 ... 27613 27614 27615]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 5)\n",
    "count = 0\n",
    "data1 = [None] * 5\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    print(\"Iteration: \", count)\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # model = GBC(n_estimators = 400, learning_rate = 0.09, verbose = 1)\n",
    "    model = GBC(n_estimators = 400, learning_rate = 0.09)\n",
    "    \n",
    "    xs, ys = balanced_subsample(X_train, y_train, 1)\n",
    "    \n",
    "    model = model.fit(xs, ys)\n",
    "    \n",
    "    yhat = model.predict(X_train)\n",
    "    tr_auc, _, _, _ = single_score(y_train, yhat)\n",
    "    \n",
    "    yhat2 = model.predict(X_test)\n",
    "    te_auc, f1_scor, sen, spec = single_score(y_test, yhat2)\n",
    "    \n",
    "    data1[count] = {'train_auc' : tr_auc, 'test_auc' : te_auc, 'test_f1_score' : f1_scor, 'test_sen(precision)' : sen, 'test_spec(recall)' : spec}\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_auc</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>test_f1_score</th>\n",
       "      <th>test_sen(precision)</th>\n",
       "      <th>test_spec(recall)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.848286</td>\n",
       "      <td>0.767540</td>\n",
       "      <td>0.438640</td>\n",
       "      <td>0.772024</td>\n",
       "      <td>0.763056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.004128</td>\n",
       "      <td>0.010340</td>\n",
       "      <td>0.009578</td>\n",
       "      <td>0.035060</td>\n",
       "      <td>0.020267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.841840</td>\n",
       "      <td>0.758347</td>\n",
       "      <td>0.426819</td>\n",
       "      <td>0.729894</td>\n",
       "      <td>0.739979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.846722</td>\n",
       "      <td>0.759013</td>\n",
       "      <td>0.430610</td>\n",
       "      <td>0.755690</td>\n",
       "      <td>0.746557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.849729</td>\n",
       "      <td>0.766044</td>\n",
       "      <td>0.441893</td>\n",
       "      <td>0.761760</td>\n",
       "      <td>0.762336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.851059</td>\n",
       "      <td>0.770683</td>\n",
       "      <td>0.444262</td>\n",
       "      <td>0.792109</td>\n",
       "      <td>0.779605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.852081</td>\n",
       "      <td>0.783613</td>\n",
       "      <td>0.449619</td>\n",
       "      <td>0.820669</td>\n",
       "      <td>0.786801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       train_auc  test_auc  test_f1_score  test_sen(precision)  \\\n",
       "count   5.000000  5.000000       5.000000             5.000000   \n",
       "mean    0.848286  0.767540       0.438640             0.772024   \n",
       "std     0.004128  0.010340       0.009578             0.035060   \n",
       "min     0.841840  0.758347       0.426819             0.729894   \n",
       "25%     0.846722  0.759013       0.430610             0.755690   \n",
       "50%     0.849729  0.766044       0.441893             0.761760   \n",
       "75%     0.851059  0.770683       0.444262             0.792109   \n",
       "max     0.852081  0.783613       0.449619             0.820669   \n",
       "\n",
       "       test_spec(recall)  \n",
       "count           5.000000  \n",
       "mean            0.763056  \n",
       "std             0.020267  \n",
       "min             0.739979  \n",
       "25%             0.746557  \n",
       "50%             0.762336  \n",
       "75%             0.779605  \n",
       "max             0.786801  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data1).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Porównanie z wynikami z artykułu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Wyniki z artykułu](results_from_article.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Otrzymane przez nas wyniki (patrząc na średnią) są porównywalne z tymi, które zostały przedstawione w artykule. W przypadku GradientBoostingClassifier jest to różnica kilku setnych, jednak w przypadku RandomForest jest to nawet około jednej dziesiątej.\n",
    "\n",
    "* Nie są to jednak te same wyniki. Jest to spowodowane tym, że autorzy artykułu nie podali optymalnych hiperparametrów dla tych modeli. \n",
    "\n",
    "* W kodzie na githubie modele są inicjowane z pewnymi hiperparametrami, jednak nie są to te, które dają optymalne wyniki zamieszczone w artykule. \n",
    "\n",
    "* Okazuje się również, że w dodatku do artukułu podano najbardziej optymalne hiperparametry dla niektórych modeli (np. SVM). Jednakże, nawet w tym przypadku wartości nie pokrywają się z tymi, które są w kodzie dla tego modelu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zapisanie wyników"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('raw_stats_rf.npy', 'wb') as f:\n",
    "    pickle.dump(data, f)\n",
    "\n",
    "with open('raw_stats_gbc.npy', 'wb') as f:\n",
    "    pickle.dump(data1, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sprawdzenie czasów uczenia modeli \n",
    "Szybciej uczące się modele mogą być lepsze, gdy będziemy tworzyć zbiory Rashomon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_time(model):\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    model.fit(X, y)\n",
    "\n",
    "    end_time = time.time()\n",
    "    return end_time-start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: 14.911872625350952\n",
      "GradientBoostingClassifier: 140.62497067451477\n",
      "[13:50:07] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBClassifier: 21.846973180770874\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "print(f\"Random Forest: {measure_time(RF(n_estimators = 450, n_jobs = -1))}\")\n",
    "print(f\"GradientBoostingClassifier: {measure_time(GBC(n_estimators = 400, learning_rate = 0.09))}\")\n",
    "print(f\"XGBClassifier: {measure_time(xgb.XGBClassifier(objective='binary:logistic', n_estimators = 400, learning_rate = 0.09, use_label_encoder=False, n_jobs = -1))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForest oraz XGBClassifier może działać wielowątkowo, dlatego są one szybsze."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
